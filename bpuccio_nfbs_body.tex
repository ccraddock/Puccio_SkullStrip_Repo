%%%%%%%%%%%%%%%%
%% Background %%
%%
\section*{Data description}

\par One of the many challenges facing the analysis of magnetic resonance imaging (MRI) data is achieving accurate brain extraction from the data. Brain extraction, also known as skull-stripping, aims to remove all non-brain tissue from an image. This is commonly a preliminary step in preprocessing and the quality of its result affects the subsequent steps, such as image registration and brain matter segmentation. Many challenges surround the process of brain extraction. The manual creation and correction of brain masks is tedious, time-consuming, and susceptible to experimenter bias. On the other hand, fully automated brain extraction is not a simple image segmentation problem. Brains differ in orientation and morphology, especially pediatric, geriatric, and pathological brains. In addition, non-brain tissue may resemble brain in terms of voxel intensity. Differences in MRI scanner, acquisition sequence, and scan parameters can also have an effect on automated algorithms due to differences in image contrast, quality, and orientation. Image segmentation techniques with low computational time, high accuracy, and high flexibility are extremely desirable.

\par Developing new automated skull-stripping methods, and comparing these with existing methods, requires large quantities of gold standard skull-stripped data acquired from a variety of scanners using a variety of sequences and parameters. This is due to the variation in performance of algorithms using different MRI data. Repositories containing gold standard skull-stripped data already exist: the Alzheimer's Disease Neuroimaging Initiative (ADNI) \cite{pmid17476317}; BrainWeb: Simulated Brain Database (SBD) \cite{brainweb}; the Internet Brain Segmentation Repository (IBSR) at the Center for Morphometric Analysis \cite{IBSR}; the LONI Probabilistic Brain Atlas (LPBA40) at the UCLA Laboratory of Neuro Imaging \cite{lpba40}; and the Open Access Series of Imaging Studies (OASIS) \cite{oasis}, the last of which is not manually delineated but has been used as gold standard data \cite{Iglesias2011, MASS}. We extend and complement these existing repositories by releasing manually corrected skull strips for 125 individuals from the Nathan Kline Institute (NKI) Enhanced Rockland Sample Neurofeedback Study (NFB). These are the first 125 participants who finished the entire 3-day protocol, consented to have their data shared, and were not excluded from data sharing for having an incidental finding during neuroradiological review.  

\subsection*{Data acquisition}

\par The repository was constructed from defaced and anonymized anatomical data downloaded from the NFB \cite{Nooner2012}. The NFB is a 3-visit study that involves a deep phenotypic assessment on the first and second visits, a 1-hour connectomic MRI scan on the second visit, and a 1-hour neurofeedback scan on the last visit. Up to 3 months may have passed between the first and last visits. The 125 participants included 77 females and 48 males in the 21--45 age range (average: 31, standard deviation: 6.6). 

Consistent with the the Research Domain Criteria (RDoC) \cite{Insel2010}, the goal of the NFB study is to examine default network regulation across a range of clinical and subclinical psychiatric symptoms. To preserve this variance, while being representative of the general population, a community-ascertained sample was recruited with minimally restrictive psychiatric exclusion criteria \cite{Nooner2012}. Only the most severe illnesses were screened out, excluding those who were unable to comply with instructions, tolerate the MRI, and participate in the extensive phenotyping protocol. As a result, 66 of the participants had one or more current or past psychiatric diagnosis as determined by the structured clinical interview for the DSM-IV (SCID) \cite{skid} (see Table \ref{psych}). No brain abnormalities or incidental findings were present in the images, as determined by a board-certified neuroradiologist. None of the participants had any other major medical condition such as cancer or AIDS.

\begin{table}[h!]
\caption{Neurofeedback Participant Diagnoses}
      \begin{tabular}{ p{7cm} p{0.4cm} }
        \textbf{Diagnosis (SCID \#)} & \textbf{\#} \\ \hline
        No diagnosis or condition on Axis I & 59  \\
        Major depressive disorder, past & 26  \\
        Alcohol abuse, past & 21  \\
        Cannabis abuse, current & 11  \\
        Cannabis dependence, past & 11  \\
        Attention-deficit/hyperactivity disorder, current & 10  \\
        Alcohol dependence, past & 5  \\
        Posttraumatic stress disorder, current & 5  \\
        Specific phobia, past & 5  \\
        Generalized anxiety disorder, current & 4  \\
        Cocaine abuse, past & 2  \\
        Cocaine dependence, past & 2  \\
        Hallucinogen abuse, past & 2  \\
        Agoraphobia without history of panic disorder, current & 2  \\
        Anorexia nervosa, past & 2  \\
        Anxiety disorder not otherwise specified, current & 2  \\
        Panic disorder with agoraphobia, past & 2  \\
        Panic disorder without agoraphobia, past & 2  \\
        Social phobia current & 2  \\
        Alcohol abuse, current & 1  \\
        Amphetamine dependence, past & 1  \\
        Bereavement & 1  \\
        Body dysmorphic disorder, current & 1  \\
        Bulimia nervosa, current & 1  \\
        Delusional disorder mixed type & 1  \\
        Eating disorder not otherwise specified, past & 1  \\
        Hallucinogen dependence, past & 1  \\
        Major depressive disorder, current & 1  \\
        Obsessive-compulsive disorder, current & 1  \\
        Opioid abuse, past  & 1  \\
        Phencyclidine abuse, past & 1  \\
        Sedative, hypnotic, or anxiolytic dependence, past & 1 \\
        Trichotillomania & 1  \\
        \hline
      \end{tabular}
\label{psych}
\end{table}

Anatomical MRI data from the third visit of the NFB protocol were used to build the Neurofeedback Skull-stripped (NFBS) repository. MRI data were collected on a 3~T Siemens Magnetom TIM Trio scanner (Siemens Medical Solutions USA: Malvern PA, USA) using a 12-channel head coil. Anatomical images were acquired at $1\times1\times1$ mm$^3$ resolution with a 3D T1-weighted magnetization-prepared rapid acquisition gradient-echo (MPRAGE)~\cite{Mugler1990} sequence in 192 sagittal partitions each with a $256\times256$ mm$^2$ field of view (FOV), 2600 ms repetition time (TR), 3.02~ms echo time (TE), 900~ms inversion time (TI), 8$^{\circ}$ flip angle (FA), and generalized auto-calibrating partially parallel acquisition (GRAPPA) acceleration~\cite{Griswold2002} factor of 2 with 32 reference lines. Anatomical data were acquired immediately after a fast localizer scan and preceded the collection of a variety of other scans~\cite{nki_mrproto}, whose description is beyond the scope of this report.

\subsection*{Brain mask definition}

\par Many researchers differ on the standard for what to include and exclude from the brain. Some brain extraction methods, such as brainwash, include the dura mater in the brain mask to use as a reference for measurements~\cite{Brainwash}. The standard we used was adapted from Eskildsen et al (2012)~\cite{Eskildsen2012}. Non-brain tissue is defined as skin, skull, eyes, dura mater, external blood vessels and nerves (e.g.,~optic chiasm, superior sagittal sinus, and transverse sinus). Cerebrum, cerebellum, brainstem, and internal vessels and arteries are included in the brain, along with cerebrospinal fluid (CSF) in ventricles, internal cisterns, and deep sulci.

\subsection*{NFBS repository construction}

\par The BEaST method (brain extraction based on nonlocal segmentation technique) was used to initially skull-strip the 125 anatomical T1-weighted images~\cite{Eskildsen2012}. This software uses a patch-based label fusion method that labels each voxel in the brain boundary volume by comparing it to similar locations in a library of segmented priors. The segmentation technique also incorporates a multi-resolution framework in order to reduce computational time. The version of BEaST used was 1.15.00 and our implementation was based on a shell script written by Qingyang Li~\cite{rpubs}. The standard parameters were used in the configuration files and beast-library-1.1 (which contains data from 10 young individuals) was used for the initial skull-strip of the data. Before running {\tt mincbeast}, the main segmentation script of BEaST, the anatomical images were normalized using the {\tt beast\_normalize} script. {\tt mincbeast} was run using the probability filter setting, which smoothed the manual edits, and the fill setting, which filled any holes in the masks. The failure rate for masks using BEaST was similar to that of the published rate of approximately 29\% \cite{Eskildsen2012}. Visual inspection of these initial skull-stripped images indicated whether additional edits were necessary.

\par Manual edits were performed using the Freeview visualization tool from the FreeSurfer software package~\cite{Fischl2012}. The anatomical image was loaded as a track volume and the brain mask was loaded as a volume. The voxel edit mode was then used to include or exclude voxels in the mask. As previously mentioned, all exterior non-brain tissue was removed from the head image, specifically the skull, scalp, fat, muscle, dura mater, and external blood vessels and nerves (see Figure~\ref{fig:edit}). Time spent editing each mask ranged from 1--8 hours, depending on the quality of the anatomical image and the BEaST mask. Afterwards, manually edited masks were used create a NFB specific prior library for BEaST. This iterative bootstrapping technique was repeated until approximately 85 of the datasets were manually edited and all skull-strips were considered acceptable.

\begin{figure}[h!]
    \includegraphics[width=0.4\textwidth]{edit.png}
    \caption{\csentence{Manual Editing}
Axial and coronal slices in the AFNI viewer of the brain mask and image pair, before and after manual editing in Freeview. The anatomical image was loaded into the viewer as a grayscale image. The mask, which can be seen in a transparent red, was loaded as an overlay image.}
\label{fig:edit}
\end{figure}

For each of the 125 subjects, the repository contains the de-faced and anonymized anatomical T1-weighted image, skull-stripped brain image, and brain mask. Each of these are in compressed NIfTI file format (.nii.gz). The size of the entire data set is around 1.9 GB. The BEaST library created using these images is also available.


\subsection*{Data validation}

The semi-automated skull-stripping procedure was repeated until all brain masks were determined to be acceptable by two raters (BP and ET). Once this was completed, the brain masks were used as gold standard data for comparing different automated skull-stripping algorithms.  Additionally, we evaluated the performance of the newly created BEaST library by comparing it to other skull-stripping methods on data from the IBSR \cite{IBSR} and the LPBA40 \cite{lpba40}.

\subsubsection*{Skull-stripping algorithms}
Many skullstripping algorithms have been developed \cite{Iglesias2011, MASS, Brainwash, Sadananthan2010, Lutkenhoff2014, Wang2014, pmid21195780, bse}, but we focused on FSL's Brain Extraction Tool (BET) \cite{Smith2002}, AFNI's 3dSkullStrip \cite{afni}, and FreeSurfer's Hybrid Watershed Algorithm (HWA) \cite{Segonne2004} based on their popularity.

\begin{itemize}
    \item BET is an algorithm incorporated in the FSL software that is based on a deformable model of the surface of the brain \cite{Smith2002}. First, an intensity histogram is used to find the center of gravity of the head. Then a tessellated sphere is initialized around the center of gravity and expanded by locally adaptive forces. The method can also incorporate T2-weighted images to isolate the inner and outer skull and scalp. The bias field and neck setting ({\tt bet -B}) was used since the anatomical images contained the subjects' necks. The version of FSL used was 5.0.7.

    \item 3dSkullStrip is a modified version of BET that is incorporated in the AFNI toolkit \cite{afni}. The algorithm begins by preprocessing the image to correct for spatial variations in image intensity and repositioning the brain to roughly the center of the image. Then a modified algorithm based on BET is used to expand a mesh sphere until it envelops the entire brain surface. Among the modifications are procedures to avoid the eyes and ventricles and operations to avoid cutting into the brain. The version of the AFNI toolkit used was AFNI\_2011\_12\_21\_1014.

    \item HWA is a hybrid technique that uses a watershed algorithm in combination with a deformable surface algorithm \cite{Segonne2004}. The watershed algorithm is first used to create an initial mask under the assumption of the connectivity of white matter. Then a deformable surface model is used to incorporate geometric constraints into the mask. The version of FreeSurfer used was 5.3.0.
\end{itemize}



\subsubsection*{Data analysis}

To illustrate the use of the NFBS as testing data, it was used to compare the performance of BET, 3dSkullStrip and HWA for automatically skull-stripping the original NFB data. In a second analysis we compared the performance of the NFBS BEaST library to the default BEaST library and the three aforementioned methods. Each of the methods was used to skull-strip data from the IBSR (version 2.0) and LPBA40 \cite{IBSR, lpba40}. To ensure consistent image orientation across methods and datasets, they were all converted to LPI orientation\footnote{This refers to the manner in which the 3D image data are saved in the file. With LPI orientation, the voxel at memory location (0,0,0) is located at the leftmost, posterior, inferior voxel in the image. As the indices increase, they scan the voxels from left-to-right, along lines that advance from posterior-to-anterior, and planes that advance from inferior-to-superior.
Additional details concerning the orientation of MRI images are available online \cite{orientation}.} using AFNI's \texttt{3dresample} program \cite{afni}. Additionally, a step function was applied to all of the outputs using AFNI's \texttt{3dcalc} tool to binarize all of the generated masks.

\par The performance of the various methods was compared using the Dice similarity \cite{Dice1945} between the mask generated for an image and its corresponding reference (`gold standard') mask. Dice was calculated using: $D = 2 \cdot | A \cap B | / (|A| + |B|)$, where $A$ is the set of voxels in the test mask, $B$ is the set of voxels in the gold standard data mask, $A \cap B$ is the intersection of $A$ and $B$, and $|\cdot|$ is the number of voxels in a set. Dice was implemented in custom Python scripts that used the NiBabel neuroimaging package \cite{NiBabel} for data input. Dice coefficients were subsequently graphed as box plots using the ggplot2 package \cite{Wickham2009} for the R statistical computing language \cite{R}.


\subsubsection*{Results}
Figure \ref{fig:boxplot_NFBS} displays box plots of the Dice coefficients that result from using NFBS as gold standard data. The results indicate that 3dSkullStrip performed significantly better than the two alternative methods, with HWA coming in second. In particular, average Dice similarity coefficients were 0.893 $\pm$ 0.027 for BET, 0.949 $\pm$ 0.009 for 3dSkullStrip, and 0.900 $\pm$ 0.011 for HWA. It is perhaps worth noting that BET, the method that performed worst on the NFBS library, took substantially more time to run (25 min) compared to 3dSkullStrip (2 min) and HWA (1 min).

\begin{figure}[h!]
    \includegraphics[]{boxplot_nfbs.pdf}
    \caption{\csentence{Comparison of methods on NFBS}. Boxplots of Dice coefficients measuring the similarity between masks generated from each image using BET, 3dSkullStrip, HWA, and the image's corresponding reference brain masks. }
    \label{fig:boxplot_NFBS}
\end{figure}

Switching now from using NFBS as the repository of gold standard skull-stripped images to using the IBSR and LPBA40 repositories as the source of gold standard images, Figure \ref{fig:boxplot_I&L} shows box plots of the Dice similarity coefficients for BET, 3dSkullStrip, HWA, BEaST using beast-library-1.1, and BEaST using NFBS as the library of priors. For IBSR, 3dSkullStrip performs better than BET and HWA, similarly to NFBS. However, for LPBA40, BET performs much better than the other two algorithms. The BEaST method was also applied to the anatomical data in these repositories using two different methods: first with the original beast-library-1.1 set as the prior library, and second with the entire NFBS set as the prior library.

For the BEaST method, using NFBS as the prior library resulted in higher average Dice similarity coefficients and smaller standard deviations\footnote{BEaST was unable to segment 1 subject, IBSR\_11, in IBSR, only when using beast-library-1.1. For LPBA40, BEaST was also unable to segment 1 subject, S35, when using beast-library-1.1 and NFBS. These subjects were left out of the Dice calculations.}. Differences in Dice coefficients between datasets may be due the size and quality of the NFB study, as well as the pathology and age of the participants. In particular, the NFBS library of priors reflects a much wider range of individuals than does beast-library-1.1, which only contains 10 young individuals. There also may be differences in the standard of the masks, such as length of brainstem and inclusion of exterior nerves and sinuses.

\begin{figure}[ht!]
\includegraphics[width=0.4\textwidth]{boxplot_IL.pdf}
    \caption{\csentence{Dice coefficients for IBSR and LPBA40.}
Box plot of Dice coefficients for BET, 3dSkullStrip, HWA, BEaST using beast-library-1.1, and BEaST using NFBS as the library of priors. One subject was left out of the Dice calculation for each of the following: BEaST with beast-library-1.1 on IBSR (IBSR\_11), BEaST with beast-library-1.1 on LPBA40 (S35), and BEaST with NFBS on LPBA40 (S35).}
\label{fig:boxplot_I&L}
\end{figure}

Placing our results in the context of other skull-stripping comparisons, differences between the Dice coefficients reported here and values already published in the literature may be due to the version and implementation of the skull stripping algorithms, a possibility that has received support in the literature \cite{Iglesias2011}. These differences may also result from our application of AFNI's 3dcalc step function to the skull-stripped images in order to get a value determined more by brain tissue and less influences by CSF. As the NFBS dataset is freely accessible by members of the neuroimaging community, these possibilities may be investigated by the interested researcher.
%Iglesias et al published Dice on IBSR as 0.938 $\pm$ 0.029 for BET, 0.945 $\pm$ 0.06 for 3dSkullStrip, and 0.879 $\pm$ 0.018 for FreeSurfer HWA

\subsection*{Importance for the neuroimaging community}

In summary, we have created and shared the NFBS repository of high quality, skull-stripped T1-weighted anatomical images that is notable for its quality, its heterogeneity, and its ease of access. The procedure used to populate the repository combined the automated, state-of-the-art BEaST algorithm with  meticulous hand editing to correct any residual brain extraction errors noticed on visual inspection. The manually corrected brain masks will be a valuable resource for improving the quality of preprocessing obtainable on the NFB data. The corresponding BEaST library will improve skull-stripping of future NFB releases and may outperform the default beast-library-1.1 on other datasets (see Figure \ref{fig:boxplot_I&L}). Additionally, the corrected brain masks may be used as gold standards for comparing alternative brain extraction algorithms, as was illustrated in our preliminary analysis (see Figure \ref{fig:boxplot_NFBS}).

The NFBS repository is larger and more heterogeneous than many comparable datasets. It contains 125 skull-stripped images, is composed of images from individuals with ages ranging from 21--45, and represents individuals diagnosed with a wide range of psychiatric disorders (see Table \ref{psych}). This variation is a crucial feature of NFBS, as it accounts for more than the average brain. Ultimately, this variation may prove useful for researchers interested in developing and evaluating predictive machine learning algorithms on both normal populations and those with brain disorders~\cite{gabrieli2015prediction}.

Finally, the repository is completely open to the neuroscience community. NFBS contains no sensitive personal health information, so researchers interested in using it may do so without submitting an application or signing a data usage agreement. This is in contrast to datasets such as the one collected by the Alzheimer's Disease Neuroimaging Initiative (ADNI) \cite{pmid17476317}. Researchers can use ADNI to develop and test skull-stripping algorithms \cite{pmid21195780}, but in order to do so must first apply and sign a data usage agreement, which bars them from distributing the results of their efforts. Thus, we feel that NFBS has the potential to accelerate the pace of discovery in the field, a view that resonates with perspectives on the importance of making neuroimaging repositories easy to access and easy to use \cite{Nichols054262}.

\section*{Availability of supporting data}
The NFBS skull-stripped repository is available at: \url{www.preprocessed-connectomes-project.org/NFB\_skullstripped}. Bash and Python scripts used to create the NFBS repository and produce the results and figures in this paper are available on GitHub at: \url{https://github.com/preprocessed-connectomes-project/NFB\_skullstripped}. Snapshots of the project and other supporting information is available in the GigaScience repository, GigaDB \cite{puccio2016}.
